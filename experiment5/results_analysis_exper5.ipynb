{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_names_small = ['U8170', 'U3277', 'U8840', 'U7311', 'U1467', 'U1789', 'U8168', 'U1581', 'U7004', 'U9763']\n",
    "user_names_moderate = ['U5254', 'U9407', 'U1592', 'U1723', 'U1106', 'U3406', 'U342', 'U1653', \n",
    "                'U20', 'U250', 'U1450', 'U1164', 'U86']\n",
    "user_names_most_active = ['U12', 'U13', 'U24', 'U78', 'U207', 'U293', 'U453', 'U679', 'U1289', 'U1480']\n",
    "loss_file_cols=['day', 'num_events', 'loss', 'red_event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_loss_data(user_name, loadmax = True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    loss_type = 'max'\n",
    "    if not loadmax:\n",
    "        loss_type = 'diff'\n",
    "    loss_files_base = '../data/exper5__all__1epoch__reverse_from_57'\n",
    "    loss_file = '{}/users_losses/{}_losses_{}.txt'.format(loss_files_base, user_name, loss_type)\n",
    "    # check if the file exist\n",
    "    if not os.path.exists(loss_file):\n",
    "        raise Exception(\"File: '{}' doesn't exist\".format(loss_file))\n",
    "\n",
    "    return pd.read_csv(loss_file, header=None, names=loss_file_cols)\n",
    "\n",
    "\n",
    "\n",
    "def process_data(loss_days):\n",
    "    \"\"\"\n",
    "        process loss_days for user and return a list of red_events dataframe\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    results = []\n",
    "    for day, group in loss_days:\n",
    "        count +=1\n",
    "        g1 = pd.DataFrame(group)\n",
    "        g1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        num_events = g1['num_events'].unique()[0]\n",
    "        g1 = g1.drop(['num_events'], axis=1)\n",
    "\n",
    "        # calc the percentile of the entries in the group.\n",
    "        percentile = [round(1 - x/num_events, 4) for x in g1.index.values]\n",
    "        percent_s = pd.Series(percentile)\n",
    "        g1['percentile'] = percent_s.values\n",
    "\n",
    "        # filter on red_events\n",
    "        red_events = g1[g1['red_event'] == 1]\n",
    "        if not red_events.empty:\n",
    "            results.append((num_events, red_events))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process users and display the red_events percentile in their days\n",
    "We'll not process 'user_names_small' since they have very few events, and usual review of activities should detect any anomalies. Our testing show that we still have the red_events having higher percentile in the day\n",
    "\n",
    "##### Here we process the files tagged with\"max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_names = user_names_most_active + user_names_moderate #+ user_names_small\n",
    "# user_names = user_names_small\n",
    "# user_names.remove('U1653')\n",
    "\n",
    "group_results = []\n",
    "\n",
    "for u in user_names:\n",
    "    try:\n",
    "        losses = load_loss_data(u)\n",
    "        loss_days = losses.groupby(['day'])\n",
    "        red_events = process_data(loss_days)\n",
    "        print('======================')\n",
    "        print('User: {}'.format(u))\n",
    "        for num_events, anomalies in red_events:\n",
    "            print('num_events:', num_events)\n",
    "            print('anomalies:\\n', anomalies)\n",
    "            group_results.append(anomalies)\n",
    "    except Exception as error:\n",
    "        print('======================')\n",
    "        print('Caught an error: ' + repr(error))\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "\n",
    "all_res = pd.concat(group_results)\n",
    "\n",
    "# plt.figure(figsize=(12,8))\n",
    "sns.set(style =\"whitegrid\", color_codes=True)\n",
    "sns.set_context(\"notebook\", font_scale=1)\n",
    "grid = sns.JointGrid(x = 'day', y = 'percentile', data = all_res, space=0, ratio=50, \n",
    "                     xlim=(30, 0), ylim=(0.6, 1))\n",
    "# grid.plot_joint(plt.scatter, color=\"r\", s=40,  linewidth=1, marker=\"+\")\n",
    "grid.plot_joint(plt.scatter, color=\"r\", s=40, marker=\"x\")\n",
    "# grid.plot_marginals(sns.rugplot, height=1, color=\"g\")\n",
    "grid.plot_marginals(sns.distplot, kde=False, color=\"g\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here we process the files tagged with\"diff\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_names = user_names_most_active + user_names_moderate\n",
    "# user_names = user_names_small\n",
    "\n",
    "group_results = []\n",
    "\n",
    "for u in user_names:\n",
    "    try:\n",
    "        losses = load_loss_data(u, False)\n",
    "        loss_days = losses.groupby(['day'])\n",
    "        red_events = process_data(loss_days)\n",
    "        print('======================')\n",
    "        print('User: {}'.format(u))\n",
    "        for num_events, anomalies in red_events:\n",
    "            print('num_events:', num_events)\n",
    "            print('anomalies:', anomalies)\n",
    "            group_results.append(anomalies)\n",
    "    except Exception as error:\n",
    "        print('======================')\n",
    "        print('Caught an error: ' + repr(error))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
