{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import char_keras_lm as lm\n",
    "from process_utils import process_file, UserConfig, decode_data, encode_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_indir = '../data/users_feats'\n",
    "users_lossdir = '../data/test/users_losses'\n",
    "users_modeldir = '../data/exper3__all__1epoch__bidi_model/users_models'\n",
    "users_logidr = '../data/test/users_logs'\n",
    "\n",
    "max_len = 120 # max length of sentence\n",
    "num_chars = 128 # our vocabulary, i.e. unique characters in text. We'll just use the first 128 (half ASCII)\n",
    "\n",
    "if not os.path.exists(users_lossdir):\n",
    "    os.makedirs(users_lossdir)\n",
    "\n",
    "if not os.path.exists(users_logidr):\n",
    "    os.makedirs(users_logidr)\n",
    "\n",
    "u = 'U13'\n",
    "day = 27\n",
    "userConfig = UserConfig()\n",
    "userConfig.user_name = u\n",
    "userConfig.feat_dir = '{0}/{1}/'.format(users_indir, u)\n",
    "userConfig.output_base_filepath = '{0}/{1}_losses'.format(users_lossdir, u)\n",
    "userConfig.model_filepath = '{0}/{1}_simple_lm.hdf5'.format(users_modeldir, u)\n",
    "userConfig.log_filepath = '{}/{}_log.txt'.format(users_logidr, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "char_lm = lm.KerasLM(userConfig)\n",
    "dataset_fname = userConfig.feat_dir+'{}.txt'.format(day)\n",
    "\n",
    "input_data, target_data, red_events = process_file(dataset_fname, num_chars, max_len)\n",
    "# print(red_events)\n",
    "print('evaluating: {} - num events: {}  - red events:{}'.format(dataset_fname, len(input_data), len(red_events)))\n",
    "\n",
    "for X in input_data[10:25]:\n",
    "    X = X.reshape((1,) + X.shape)\n",
    "    print('X:', decode_data(X).strip())\n",
    "    y_ = char_lm.model.predict(X, batch_size=1, verbose=2)\n",
    "    res = ''.join([chr(np.argmax(x)) for x in y_[0]]).strip()\n",
    "    print('y_:', res)\n",
    "    print('\\n=========================================\\n')\n",
    "    \n",
    "## testing output for red events\n",
    "# print('Checking red events...')\n",
    "# for i, e in red_events:\n",
    "#     data = e[-1].split('|')\n",
    "#     text= [','.join(data[0:])]\n",
    "#     X, _ = encode_data(text, num_chars, max_len)\n",
    "#     print('X:', decode_data(X).strip())\n",
    "#     y_ = char_lm.model.predict(X, batch_size=1, verbose=2)\n",
    "#     res = ''.join([chr(np.argmax(x)) for x in y_[0]]).strip()\n",
    "#     print('y_:', res)\n",
    "#     print('\\n=========================================\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "char_lm = lm.KerasLM(userConfig)\n",
    "dataset_fname = userConfig.feat_dir+'{}.txt'.format(day)\n",
    "\n",
    "input_data, target_data, red_events = process_file(dataset_fname, num_chars, max_len)\n",
    "# print(red_events)\n",
    "print('evaluating: {} - num events: {}  - red events:{}'.format(dataset_fname, len(input_data), len(red_events)))\n",
    "  \n",
    "\n",
    "## testing jaccard similarity of the results\n",
    "print('\\n<<<<<======== Jaccard Similarity =========>>>>>\\n')\n",
    "\n",
    "## testing output for red events\n",
    "min_js = 0\n",
    "print('Checking red events...')\n",
    "for i, e in red_events:\n",
    "    data = e[-1].split('|')\n",
    "    text= [','.join(data[0:])]\n",
    "    X, _ = encode_data(text, num_chars, max_len)\n",
    "    y = [c for c in text[0] if c != '\\n']\n",
    "    print('y :', ''.join(y))\n",
    "    y_ = char_lm.model.predict(X, batch_size=1, verbose=2)\n",
    "    y_ = [chr(np.argmax(x)) for x in y_[0]]\n",
    "    y_ = [x for x in y_ if x != '\\n']\n",
    "    y_ = y_[:len(y)]\n",
    "    y_d = ''.join(y_).strip()\n",
    "    print('y_:', y_d)\n",
    "    js = jaccard_similarity_score(y, y_)\n",
    "    min_js = max(min_js, js)\n",
    "    print('similarity:', js)\n",
    "    print('\\n=========================================\\n')\n",
    "\n",
    "verbose = True\n",
    "if min_js == 0:\n",
    "    min_js = 0.8\n",
    "    verbose = False\n",
    "\n",
    "all_sim = []\n",
    "count = 0\n",
    "print('Checking all events...')\n",
    "for X, y in list(zip(input_data, target_data)):\n",
    "    X = X.reshape((1,) + X.shape)\n",
    "    y = y.reshape((1,) + y.shape)\n",
    "    yd = decode_data(y)\n",
    "    y = [c for c in yd if c != '\\n']\n",
    "    y_ = char_lm.model.predict(X, batch_size=1, verbose=2)\n",
    "    y_ = [chr(np.argmax(x)) for x in y_[0]]\n",
    "    y_ = [x for x in y_ if x != '\\n']\n",
    "    y_ = y_[:len(y)]\n",
    "    y_d = ''.join(y_).strip()\n",
    "    js = jaccard_similarity_score(y, y_)\n",
    "    if js < (min_js + 0.001):\n",
    "        if verbose:\n",
    "            print('y :', yd.strip())\n",
    "            print('y_:', y_d)\n",
    "            print('similarity:', js)\n",
    "        count +=1\n",
    "    all_sim.append(js)\n",
    "#     print('\\n=========================================\\n')\n",
    "\n",
    "print('\\n => # events below {}:{}'.format(min_js+0.001, count))\n",
    "print('\\n => avg similarity:', np.mean(all_sim))\n",
    "plt.figure()\n",
    "plt.plot(all_sim)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
