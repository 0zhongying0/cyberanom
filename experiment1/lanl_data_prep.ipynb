{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "\n",
    "Some of the concepts and functions are taken from the safekit source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth_fname = \"./data/auth_100M.txt\"\n",
    "redteam_fname = \"./data/redteam.txt\"\n",
    "char_features_fname = \"./data/char_features.txt\"\n",
    "redteam_lines_fname = \"./data/redteam_lines.txt\"\n",
    "\n",
    "char_feats_dir = './data/char_feats/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_line(long_line, pad_len):\n",
    "    '''\n",
    "        log line: line to be translated, \n",
    "        pad_len : the number of 0's to append so that the length of the translated line is the same in the dataset \n",
    "                  (character-wise). \n",
    "        \n",
    "        note - 0 and 1 are used to describe START and END of the translated sentence.\n",
    "    '''\n",
    "    return \"0 \" + \" \".join([str(ord(c) - 30) for c in long_line]) + \" 1 \" + \" \".join([\"0\"] * pad_len) + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note1\n",
    "*There is a difference on what the source in LANL_LM_data.ipynp is trying to filter and the format of the auth.txt file. For simplicity we'll just use the whole line length*\n",
    "\n",
    "*Here is the original code as a reference*\n",
    "```\n",
    "max_len = 0\n",
    "with open(\"auth_proc.txt\", \"r\") as infile:\n",
    "    for line in infile:\n",
    "        tmp = line.strip().split(',')\n",
    "        line_minus_time = tmp[0] + ',' + ','.join(tmp[2:])\n",
    "        if len(line_minus_time) > max_len:\n",
    "            max_len = len(line)\n",
    "print (max_len)*\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_line_length:  113\n",
      "number of lines:  100000000\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the max log line in auth.txt (note: we are using a subset auth_100M.txt for trials)\n",
    "\n",
    "max_len = 0\n",
    "num_lines = 0\n",
    "with open(auth_fname, \"r\") as infile:\n",
    "    for line in infile:\n",
    "        num_lines += 1\n",
    "        if len(line) > max_len:\n",
    "            max_len = len(line)\n",
    "print ('max_line_length: ', max_len)\n",
    "print ('number of lines: ', num_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# original notebook filter the following days as weekend.\n",
    "# we are not sure where they got the exact numbers from.\n",
    "weekend_days = [3, 4, 10, 11, 17, 18, 24, 25, 31, 32, 38, 39, 45, 46, 47, 52, 53]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note2\n",
    "*It's not clear how the original notebook deal with the file segments. which is described here*\n",
    "```\n",
    "Each event is on a separate line in the form of \"time,user@domain,computer,process name,start/end\" and represents a process event at the given time.\n",
    "```\n",
    "so, we decided to use such description. For now we'll ignore marking the redteam events to see if we can discover them during inference, we'll also include all days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000000/100000000 [19:53<00:00, 83804.21it/s]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from tqdm import trange \n",
    "\n",
    "redevents = set()\n",
    "\n",
    "red_outfile = open(redteam_lines_fname, \"w\")\n",
    "with open(redteam_fname, 'r') as red:\n",
    "    for line in red:\n",
    "        redevents.add(line.strip())\n",
    "\n",
    "#print(redevents)\n",
    "\n",
    "# parse the data file, reading in (raw) and writing out (translated) log lines.\n",
    "with open(auth_fname, 'r') as infile, open(char_features_fname, 'w') as outfile:\n",
    "    outfile.write('line_num sec day user red seq_len sentence\\n') # header\n",
    "#     infile.readline()\n",
    "    for line_num in trange(num_lines):\n",
    "        raw_line = infile.readline().strip().split(',')\n",
    "        line_minus_time = ','.join(raw_line[1:])\n",
    "        diff = max_len - len(line_minus_time)\n",
    "        sec = raw_line[0]\n",
    "        day = math.floor(int(sec)/86400)\n",
    "        user = raw_line[1].strip().split('@')[0]\n",
    "        red = 0\n",
    "        redentry = \"{0},{1},{2},{3}\".format(raw_line[0], raw_line[1], raw_line[3], raw_line[4])\n",
    "#         line_minus_event = \",\".join(raw_line[1:])\n",
    "#         red += int(line_minus_event in redevents) # 1 if line is red event\n",
    "#         if user.startswith('U') and day not in weekend_days:\n",
    "        if user.startswith('U'):\n",
    "            translated_line = translate_line(line_minus_time, diff)\n",
    "            outfile.write(\"%s %s %s %s %s %s %s\" % (line_num, sec, day, \n",
    "                                                    user.replace(\"U\", \"\"), \n",
    "                                                    red, len(line_minus_time) + 1, translated_line))\n",
    "            \n",
    "            # tag the redteam entry with a line number correspond to the processed line\n",
    "            if redentry in redevents:\n",
    "                #print(redentry)\n",
    "                red_outfile.write(\"{0},{1}\\n\".format(line_num, redentry))\n",
    "    \n",
    "    outfile.close()\n",
    "    red_outfile.close()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final preprocessing step is to split the translated data into multiple files; one for each day.\n",
    "\n",
    "import os\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "if not os.path.exists(char_feats_dir):\n",
    "    os.makedirs(char_feats_dir)\n",
    "    \n",
    "num_data_lines = 0\n",
    "print(\"get number of lines in {0} file\".format(char_features_fname))\n",
    "\n",
    "with open(char_features_fname, 'r') as data:\n",
    "    for x in data:\n",
    "        num_data_lines +=1\n",
    "    \n",
    "with open(char_features_fname, 'r') as data:\n",
    "    current_day = '0'\n",
    "    data.readline() # skip the header\n",
    "    outfile = open(char_feats_dir + current_day + '.txt', 'w')\n",
    "    for i in trange(num_data_lines):\n",
    "        try:\n",
    "            line = data.readline()\n",
    "            if not line:\n",
    "                continue\n",
    "            larray = line.strip().split(' ')\n",
    "            if int(larray[2]) == int(current_day):\n",
    "                outfile.write(line)\n",
    "            else:\n",
    "                outfile.close()\n",
    "                current_day = larray[2]\n",
    "                outfile = open(char_feats_dir + current_day + '.txt', 'w')\n",
    "                outfile.write(line)\n",
    "        except:\n",
    "            print('error processing file.')\n",
    "    outfile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
